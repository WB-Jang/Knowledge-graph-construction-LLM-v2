{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul2Z153XeWph"
      },
      "source": [
        "# ğŸ›ï¸ Legal Knowledge Graph v2 - Google Colab Edition\n",
        "\n",
        "í•œêµ­ì–´ ë²•ë¥  ë¬¸ì„œë¥¼ Google Gemini APIë¥¼ í™œìš©í•˜ì—¬ ì§€ì‹ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ëŠ” ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥\n",
        "- âœ… GPU ê°€ì† ì§€ì› (T4)\n",
        "- âœ… Google Gemini API ì—°ë™\n",
        "- âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)\n",
        "- âœ… ë²•ë¥  ì¡°í•­ ìë™ ë¶„ë¦¬\n",
        "- âœ… ì§€ì‹ ê·¸ë˜í”„ ìƒì„±\n",
        "- âœ… ê²°ê³¼ JSON ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
        "- âœ… í•œê¸€ ì§€ì›"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M48xva-0eWpi"
      },
      "source": [
        "## 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD3EO2GeeWpj",
        "outputId": "757090bb-3d1c-4d67-dc65-007105f87b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GPU ì‚¬ìš© ê°€ëŠ¥:\n",
            "Wed Dec 24 08:29:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GPU í™•ì¸\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    print(\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥:\")\n",
        "    print(result.stdout)\n",
        "except FileNotFoundError:\n",
        "    print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtiwH9dUeWpj",
        "outputId": "0fb071f1-4d0c-48e4-9a6e-349696965e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knowledge-graph-construction-LLM-v2'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (267/267), done.\u001b[K\n",
            "remote: Compressing objects: 100% (214/214), done.\u001b[K\n",
            "remote: Total 267 (delta 117), reused 126 (delta 39), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (267/267), 143.49 KiB | 8.97 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "/content/Knowledge-graph-construction-LLM-v2\n"
          ]
        }
      ],
      "source": [
        "# ì €ì¥ì†Œ í´ë¡ \n",
        "!git clone https://github.com/WB-Jang/Knowledge-graph-construction-LLM-v2.git\n",
        "%cd Knowledge-graph-construction-LLM-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMFoL1IseWpk",
        "outputId": "9c8f09ef-be5f-4e44-ad0e-bbdc321ee951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "!pip install -q langchain langchain-community langchain-google-genai langgraph\n",
        "!pip install -q google-generativeai langchain-core\n",
        "!pip install -q pydantic python-dotenv\n",
        "!pip install -q rich tqdm\n",
        "!pip install -q PyMuPDF\n",
        "\n",
        "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8II6XCseWpl",
        "outputId": "0ee40e92-9e0a-4238-87f8-dcd916c2b1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n",
            "âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)\n",
        "!apt-get install -qq fonts-nanum\n",
        "!fc-cache -fv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# ë‚˜ëˆ” í°íŠ¸ ì„¤ì •\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_prop = fm.FontProperties(fname=font_path)\n",
        "plt.rcParams['font.family'] = font_prop.get_name()\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti3ur63FeWpm"
      },
      "source": [
        "## 2ï¸âƒ£ API í‚¤ ì„¤ì •\n",
        "\n",
        "Google AI Studioì—ì„œ Gemini API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”: https://makersuite.google.com/app/apikey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Q-ihngeWpm",
        "outputId": "285e07aa-f3df-4ab3-d3f8-0a48f1ec546d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Gemini API í‚¤ ì…ë ¥\n",
        "api_key = getpass(\"Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "os.environ[\"USE_LOCAL_LLM\"] = \"false\"\n",
        "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash-preview-09-2025\"\n",
        "os.environ[\"LLM_TEMPERATURE\"] = \"0.0\"\n",
        "os.environ[\"LLM_MAX_TOKENS\"] = \"2048\"\n",
        "\n",
        "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdwRonCCeWpn"
      },
      "source": [
        "## 3ï¸âƒ£ Colabìš© ê°„ì†Œí™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\n",
        "\n",
        "Colab í™˜ê²½ì—ì„œëŠ” Memgraphë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ë©”ëª¨ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê°„ì†Œí™”ëœ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNTHuqb4eWpn",
        "outputId": "0d87a72c-8075-4030-e314-04e8e5291a95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Colabìš© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# Colabìš© ê°„ì†Œí™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\n",
        "colab_script = '''\n",
        "\"\"\"Colabìš© ê°„ì†Œí™” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
        "sys.path.insert(0, \"/content/Knowledge-graph-construction-LLM-v2/src\")\n",
        "\n",
        "from models.schemas import LegalDocument, LegalEntity, GraphTriplet\n",
        "from graphs.legal_graph import LegalKnowledgeGraphWorkflow\n",
        "from utils.text_processor import split_articles\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "console = Console()\n",
        "\n",
        "def process_document(title: str, law_number: str, content: str, max_articles: int = 3) -> LegalDocument:\n",
        "    \"\"\"ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
        "    console.print(f\"ğŸš€ [{title}] ì²˜ë¦¬ ì‹œì‘...\", style=\"bold green\")\n",
        "\n",
        "    # ì¡°í•­ ë¶„ë¦¬\n",
        "    articles = split_articles(content)\n",
        "    console.print(f\"ğŸ“„ ë°œê²¬ëœ ì¡°í•­: {len(articles)}ê°œ\")\n",
        "\n",
        "    # Colabì—ì„œëŠ” ì²˜ìŒ max_articlesê°œë§Œ ì²˜ë¦¬ (API ì œí•œ ê³ ë ¤)\n",
        "    if len(articles) > max_articles:\n",
        "        console.print(f\"âš ï¸ Colab í™˜ê²½: ì²˜ìŒ {max_articles}ê°œ ì¡°í•­ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤\", style=\"yellow\")\n",
        "        content_limited = \"\\n\\n\".join(articles[:max_articles])\n",
        "    else:\n",
        "        content_limited = content\n",
        "\n",
        "    document = LegalDocument(\n",
        "        title=title,\n",
        "        law_number=law_number,\n",
        "        content=content_limited\n",
        "    )\n",
        "\n",
        "    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
        "    workflow = LegalKnowledgeGraphWorkflow()\n",
        "\n",
        "    with console.status(\"[bold green]ì²˜ë¦¬ ì¤‘...\", spinner=\"dots\"):\n",
        "        result = workflow.process(document)\n",
        "\n",
        "    console.print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ!\", style=\"bold green\")\n",
        "    console.print(f\"   ì¶”ì¶œëœ ê°œì²´: {len(result.entities)}ê°œ\")\n",
        "    console.print(f\"   ì¶”ì¶œëœ ê´€ê³„: {len(result.triplets)}ê°œ\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def display_results(document: LegalDocument):\n",
        "    \"\"\"ê²°ê³¼ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\"\"\"\n",
        "    # ê°œì²´ í…Œì´ë¸”\n",
        "    if document.entities:\n",
        "        entity_table = Table(title=f\"ğŸ“Š ì¶”ì¶œëœ ê°œì²´ ({len(document.entities)}ê°œ)\")\n",
        "        entity_table.add_column(\"ì¡°í•­\", style=\"cyan\")\n",
        "        entity_table.add_column(\"ê°œë…\", style=\"magenta\")\n",
        "        entity_table.add_column(\"ì£¼ì²´\", style=\"green\")\n",
        "        entity_table.add_column(\"í–‰ìœ„\", style=\"yellow\")\n",
        "\n",
        "        for entity in document.entities[:10]:\n",
        "            entity_table.add_row(\n",
        "                entity.article_number,\n",
        "                entity.concept[:30],\n",
        "                entity.subject or \"-\",\n",
        "                entity.action or \"-\"\n",
        "            )\n",
        "\n",
        "        console.print(entity_table)\n",
        "\n",
        "    # ê´€ê³„ í…Œì´ë¸”\n",
        "    if document.triplets:\n",
        "        relation_table = Table(title=f\"ğŸ”— ì¶”ì¶œëœ ê´€ê³„ ({len(document.triplets)}ê°œ)\")\n",
        "        relation_table.add_column(\"ì£¼ì²´\", style=\"cyan\")\n",
        "        relation_table.add_column(\"ê´€ê³„\", style=\"magenta\")\n",
        "        relation_table.add_column(\"ëŒ€ìƒ\", style=\"green\")\n",
        "        relation_table.add_column(\"ì‹ ë¢°ë„\", style=\"yellow\")\n",
        "\n",
        "        for triplet in document.triplets[:10]:\n",
        "            relation_table.add_row(\n",
        "                triplet.subject[:20],\n",
        "                triplet.relation,\n",
        "                triplet.object[:20],\n",
        "                f\"{triplet.confidence:.2f}\"\n",
        "            )\n",
        "\n",
        "        console.print(relation_table)\n",
        "\n",
        "def save_to_json(document: LegalDocument, output_path: str = \"result.json\"):\n",
        "    \"\"\"ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
        "    data = {\n",
        "        \"title\": document.title,\n",
        "        \"law_number\": document.law_number,\n",
        "        \"entities\": [entity.model_dump() for entity in document.entities],\n",
        "        \"triplets\": [triplet.model_dump() for triplet in document.triplets]\n",
        "    }\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    console.print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}\", style=\"bold green\")\n",
        "    return output_path\n",
        "'''\n",
        "\n",
        "# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±\n",
        "with open('colab_runner.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(colab_script)\n",
        "\n",
        "print(\"âœ… Colabìš© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b666d53",
        "outputId": "401e77a6-f17c-48f2-b164-be3af62f7595"
      },
      "source": [
        "import os\n",
        "\n",
        "file_path = '/content/Knowledge-graph-construction-LLM-v2/src/graphs/legal_graph.py'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# ëª¨ë“  ìƒëŒ€ ê²½ë¡œ ì„í¬íŠ¸ë¥¼ ì ˆëŒ€ ê²½ë¡œ ì„í¬íŠ¸ë¡œ ë³€ê²½\n",
        "modified_content = content.replace('from ..models.schemas', 'from models.schemas')\n",
        "modified_content = modified_content.replace('from ..chains.entity_extraction_chain', 'from chains.entity_extraction_chain')\n",
        "modified_content = modified_content.replace('from ..chains.relation_extraction_chain', 'from chains.relation_extraction_chain')\n",
        "modified_content = modified_content.replace('from ..utils.text_processor', 'from utils.text_processor')\n",
        "\n",
        "with open(file_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(modified_content)\n",
        "\n",
        "print(f\"âœ… '{file_path}' íŒŒì¼ì˜ ì„í¬íŠ¸ êµ¬ë¬¸ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… '/content/Knowledge-graph-construction-LLM-v2/src/graphs/legal_graph.py' íŒŒì¼ì˜ ì„í¬íŠ¸ êµ¬ë¬¸ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "161aa002"
      },
      "source": [
        "íŒŒì¼ ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ìƒ˜í”Œ ì‹¤í–‰ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ë³€ê²½ ì‚¬í•­ì„ ì ìš©í•´ ì£¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6dW7vREeWpo"
      },
      "source": [
        "## 4ï¸âƒ£ ìƒ˜í”Œ ì‹¤í–‰ (ê°œì¸ì •ë³´ë³´í˜¸ë²•)\n",
        "\n",
        "ìƒ˜í”Œ ë²•ë¥  í…ìŠ¤íŠ¸ë¡œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "tsySmZSneWpo",
        "outputId": "f7378cc6-3a86-402b-bc4d-50edf4f6aa72"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'if' statement on line 13 (entity_extraction_chain.py, line 14)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"/tmp/ipython-input-2952570459.py\"\u001b[0m, line \u001b[1;32m12\u001b[0m, in \u001b[1;35m<cell line: 0>\u001b[0m\n    importlib.reload(chains.entity_extraction_chain)\n",
            "  File \u001b[1;32m\"/usr/lib/python3.12/importlib/__init__.py\"\u001b[0m, line \u001b[1;32m131\u001b[0m, in \u001b[1;35mreload\u001b[0m\n    _bootstrap._exec(spec, module)\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m866\u001b[0m, in \u001b[1;35m_exec\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m995\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m1133\u001b[0m, in \u001b[1;35mget_code\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m1063\u001b[0m, in \u001b[1;35msource_to_code\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0;36m, line \u001b[0;32m488\u001b[0;36m, in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/Knowledge-graph-construction-LLM-v2/src/chains/entity_extraction_chain.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 13\n"
          ]
        }
      ],
      "source": [
        "# Colab ëŸ¬ë„ˆ ì„í¬íŠ¸\n",
        "import sys\n",
        "sys.path.insert(0, '/content/Knowledge-graph-construction-LLM-v2/src')\n",
        "\n",
        "# Explicitly reload modules after modification\n",
        "import importlib\n",
        "\n",
        "# Reloading in reverse dependency order\n",
        "# Reload entity_extraction_chain and relation_extraction_chain first\n",
        "try:\n",
        "    import chains.entity_extraction_chain\n",
        "    importlib.reload(chains.entity_extraction_chain)\n",
        "except (NameError, ModuleNotFoundError): # ModuleNotFoundError can occur if not yet loaded\n",
        "    print(\"chains.entity_extraction_chain not yet loaded or import failed, skipping reload.\")\n",
        "try:\n",
        "    import chains.relation_extraction_chain\n",
        "    importlib.reload(chains.relation_extraction_chain)\n",
        "except (NameError, ModuleNotFoundError):\n",
        "    print(\"chains.relation_extraction_chain not yet loaded or import failed, skipping reload.\")\n",
        "\n",
        "# Then reload legal_graph\n",
        "try:\n",
        "    import graphs.legal_graph\n",
        "    importlib.reload(graphs.legal_graph)\n",
        "except (NameError, ModuleNotFoundError):\n",
        "    print(\"graphs.legal_graph not yet loaded or import failed, skipping reload.\")\n",
        "\n",
        "# Finally reload colab_runner\n",
        "try:\n",
        "    import colab_runner\n",
        "    importlib.reload(colab_runner)\n",
        "except (NameError, ModuleNotFoundError):\n",
        "    print(\"colab_runner not yet loaded or import failed, skipping reload.\")\n",
        "\n",
        "\n",
        "from colab_runner import process_document, display_results, save_to_json\n",
        "\n",
        "# ìƒ˜í”Œ ë²•ë¥  ë¬¸ì„œ\n",
        "sample_content = \"\"\"\n",
        "ì œ1ì¡°(ëª©ì ) ì´ ë²•ì€ ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ ë° ë³´í˜¸ì— ê´€í•œ ì‚¬í•­ì„ ì •í•¨ìœ¼ë¡œì¨ ê°œì¸ì˜ ììœ ì™€ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ê³ , ë‚˜ì•„ê°€ ê°œì¸ì˜ ì¡´ì—„ê³¼ ê°€ì¹˜ë¥¼ êµ¬í˜„í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\n",
        "\n",
        "ì œ2ì¡°(ì •ì˜) ì´ ë²•ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
        "1. \"ê°œì¸ì •ë³´\"ë€ ì‚´ì•„ ìˆëŠ” ê°œì¸ì— ê´€í•œ ì •ë³´ë¡œì„œ ì„±ëª…, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ì˜ìƒ ë“±ì„ í†µí•˜ì—¬ ê°œì¸ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ë§í•œë‹¤.\n",
        "\n",
        "ì œ3ì¡°(ê°œì¸ì •ë³´ ë³´í˜¸ ì›ì¹™) â‘  ê°œì¸ì •ë³´ì²˜ë¦¬ìëŠ” ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ ëª©ì ì„ ëª…í™•í•˜ê²Œ í•˜ì—¬ì•¼ í•˜ê³  ê·¸ ëª©ì ì— í•„ìš”í•œ ë²”ìœ„ì—ì„œ ìµœì†Œí•œì˜ ê°œì¸ì •ë³´ë§Œì„ ì ë²•í•˜ê³  ì •ë‹¹í•˜ê²Œ ìˆ˜ì§‘í•˜ì—¬ì•¼ í•œë‹¤.\n",
        "\"\"\".strip()\n",
        "\n",
        "# ë¬¸ì„œ ì²˜ë¦¬ (ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ)\n",
        "result = process_document(\n",
        "    title=\"ê°œì¸ì •ë³´ ë³´í˜¸ë²•\",\n",
        "    law_number=\"ë²•ë¥  ì œ18583í˜¸\",\n",
        "    content=sample_content,\n",
        "    max_articles=3\n",
        ")\n",
        "\n",
        "# ê²°ê³¼ í‘œì‹œ\n",
        "display_results(result)\n",
        "\n",
        "# JSONìœ¼ë¡œ ì €ì¥\n",
        "json_path = save_to_json(result, \"sample_result.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ¨ ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "597a6c5f",
        "outputId": "75a2c155-6c00-4ba8-a460-4c6fe93f6be9"
      },
      "source": [
        "import os\n",
        "\n",
        "file_path_relation = '/content/Knowledge-graph-construction-LLM-v2/src/chains/relation_extraction_chain.py'\n",
        "\n",
        "# --- RelationExtractionChain.py content ---\n",
        "relation_content = \"\"\"from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from typing import List\n",
        "from models.schemas import GraphTriplet, LegalEntity\n",
        "from llm.gemini_client import get_llm as gemini_llm\n",
        "import os\n",
        "\n",
        "_USE_LOCAL_LLM_AT_MODULE_LEVEL = os.getenv(\"USE_LOCAL_LLM\", \"true\").lower() == \"true\"\n",
        "if _USE_LOCAL_LLM_AT_MODULE_LEVEL:\n",
        "    from llm.llama_client import get_llm as opensource_llm\n",
        "else:\n",
        "    def opensource_llm(*args, **kwargs):\n",
        "        raise RuntimeError(\"Attempted to call opensource_llm when USE_LOCAL_LLM is false at module level.\")\n",
        "\n",
        "class RelationExtractionChain:\n",
        "    def __init__(self, temperature: float = 0.0):\n",
        "        _use_local_llm_env = os.getenv(\"USE_LOCAL_LLM\", \"true\")\n",
        "        _use_local_llm_bool = _use_local_llm_env.lower() == \"true\"\n",
        "        print(f\"[DEBUG {self.__class__.__name__}] USE_LOCAL_LLM_ENV: {_use_local_llm_env}, BOOL: {_use_local_llm_bool}\")\n",
        "        if _use_local_llm_bool:\n",
        "            print(f\"[DEBUG {self.__class__.__name__}] Using opensource_llm (Llama)\")\n",
        "            self.llm = opensource_llm()\n",
        "        else:\n",
        "            print(f\"[DEBUG {self.__class__.__name__}] Using gemini_llm\")\n",
        "            self.llm = gemini_llm(temperature)\n",
        "\n",
        "        self.parser = PydanticOutputParser(pydantic_object=GraphTriplet)\n",
        "        self.prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", '''ë‹¹ì‹ ì€ ì œê³µëœ ë²•ë¥  ë¬¸ì„œì™€ ì¶”ì¶œëœ ê°œì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê³„(íŠ¸ë¦¬í”Œë ›)ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤.\\nê° ê´€ê³„ëŠ” ì£¼ì²´(subject), ê´€ê³„(relation), ëŒ€ìƒ(object)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\\nê´€ê³„ì— ëŒ€í•œ ì‹ ë¢°ë„(confidence) ì ìˆ˜ë„ 0.0ì—ì„œ 1.0 ì‚¬ì´ë¡œ í‰ê°€í•˜ì„¸ìš”.\\n\\n{format_instructions}\\nì¶”ì¶œëœ ê°œì²´: {entities}\\në²•ë¥  ì¡°í•­: {article}'''),\n",
        "            ]\n",
        "        ).partial(format_instructions=self.parser.get_format_instructions())\n",
        "\n",
        "        self.chain = self.prompt | self.llm | self.parser\n",
        "\n",
        "    def _create_chain(self):\n",
        "        return self.chain\n",
        "\n",
        "    def extract_relations(self, article: str, entities: List[LegalEntity]) -> List[GraphTriplet]:\n",
        "        try:\n",
        "            return self.chain.invoke({\"article\": article, \"entities\": entities})\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ê´€ê³„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            return []\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path_relation, 'w', encoding='utf-8') as f:\n",
        "    f.write(relation_content)\n",
        "print(f\"âœ… '{file_path_relation}' íŒŒì¼ì˜ ë‚´ìš©ì´ ì™„ì „íˆ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2124050250.py, line 35)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2124050250.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    (\"system\", \"\"\"ë‹¹ì‹ ì€ ì œê³µëœ ë²•ë¥  ë¬¸ì„œì™€ ì¶”ì¶œëœ ê°œì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê³„(íŠ¸ë¦¬í”Œë ›)ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤.\\nê° ê´€ê³„ëŠ” ì£¼ì²´(subject), ê´€ê³„(relation), ëŒ€ìƒ(object)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\\nê´€ê³„ì— ëŒ€í•œ ì‹ ë¢°ë„(confidence) ì ìˆ˜ë„ 0.0ì—ì„œ 1.0 ì‚¬ì´ë¡œ í‰ê°€í•˜ì„¸ìš”.\\n\\n{format_instructions}\\nì¶”ì¶œëœ ê°œì²´: {entities}\\në²•ë¥  ì¡°í•­: {article}\"\"\"),\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "new_cell_id_for_fix_entity_chain",
        "outputId": "b7231f87-0474-4af5-ff9e-477fa048ea73"
      },
      "source": [
        "import os\n",
        "\n",
        "file_path_entity = '/content/Knowledge-graph-construction-LLM-v2/src/chains/entity_extraction_chain.py'\n",
        "\n",
        "# --- EntityExtractionChain.py content ---\n",
        "entity_content = \"\"\"from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from typing import List\n",
        "from models.schemas import LegalEntity\n",
        "from llm.gemini_client import get_llm as gemini_llm\n",
        "import os\n",
        "\n",
        "_USE_LOCAL_LLM_AT_MODULE_LEVEL = os.getenv(\"USE_LOCAL_LLM\", \"true\").lower() == \"true\"\n",
        "if _USE_LOCAL_LLM_AT_MODULE_LEVEL:\n",
        "    from llm.llama_client import get_llm as opensource_llm\n",
        "else:\n",
        "    def opensource_llm(*args, **kwargs):\n",
        "        raise RuntimeError(\"Attempted to call opensource_llm when USE_LOCAL_LLM is false at module level.\")\n",
        "\n",
        "class EntityExtractionChain:\n",
        "    def __init__(self, temperature: float = 0.0):\n",
        "        _use_local_llm_env = os.getenv(\"USE_LOCAL_LLM\", \"true\")\n",
        "        _use_local_llm_bool = _use_local_llm_env.lower() == \"true\"\n",
        "        print(f\"[DEBUG {self.__class__.__name__}] USE_LOCAL_LLM_ENV: {_use_local_llm_env}, BOOL: {_use_local_llm_bool}\")\n",
        "        if _use_local_llm_bool:\n",
        "            print(f\"[DEBUG {self.__class__.__name__}] Using opensource_llm (Llama)\")\n",
        "            self.llm = opensource_llm()\n",
        "        else:\n",
        "            print(f\"[DEBUG {self.__class__.__name__}] Using gemini_llm\")\n",
        "            self.llm = gemini_llm(temperature)\n",
        "\n",
        "        self.parser = PydanticOutputParser(pydantic_object=LegalEntity)\n",
        "        self.prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", '''ë‹¹ì‹ ì€ ë²•ë¥  ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ê°œì²´ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤.\\nì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:\\n- ì¡°í•­ ë²ˆí˜¸ (article_number)\\n- í•µì‹¬ ê°œë… (concept): ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•œ ì§§ì€ êµ¬ë¬¸ì…ë‹ˆë‹¤.\\n- ì£¼ì²´ (subject): ê°œë…ì— ì˜í•´ ìˆ˜í–‰ë˜ëŠ” ì£¼ìš” í–‰ë™ì˜ í–‰ìœ„ìì…ë‹ˆë‹¤.\\n- í–‰ìœ„ (action): ì£¼ì²´ê°€ ìˆ˜í–‰í•˜ëŠ” ë™ì‚¬ ë˜ëŠ” ë™ì‚¬êµ¬ì…ë‹ˆë‹¤.\\n\\në§Œì•½ ì¡°í•­ ë²ˆí˜¸ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'Unknown'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ í•µì‹¬ ê°œë…ì„ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'Unknown'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ ì£¼ì²´ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ nullë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ í–‰ìœ„ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ nullë¡œ í‘œê¸°í•˜ì„¸ìš”.\\n\\n{format_instructions}\\në²•ë¥  ì¡°í•­: {article}'''),\n",
        "            ]\n",
        "        ).partial(format_instructions=self.parser.get_format_instructions())\n",
        "\n",
        "        self.chain = self.prompt | self.llm | self.parser\n",
        "\n",
        "    def _create_chain(self):\n",
        "        return self.chain\n",
        "\n",
        "    def extract_entities(self, article: str) -> List[LegalEntity]:\n",
        "        try:\n",
        "            return self.chain.invoke({\"article\": article})\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ê°œì²´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            return []\n",
        "\"\"\"\n",
        "\n",
        "with open(file_path_entity, 'w', encoding='utf-8') as f:\n",
        "    f.write(entity_content)\n",
        "print(f\"âœ… '{file_path_entity}' íŒŒì¼ì˜ ë‚´ìš©ì´ ì™„ì „íˆ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1808835994.py, line 35)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1808835994.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    (\"system\", \"\"\"ë‹¹ì‹ ì€ ë²•ë¥  ë¬¸ì„œì—ì„œ ì¤‘ìš”í•œ ê°œì²´ë¥¼ ì¶”ì¶œí•˜ëŠ” ìœ ëŠ¥í•œ ë¹„ì„œì…ë‹ˆë‹¤.\\nì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:\\n- ì¡°í•­ ë²ˆí˜¸ (article_number)\\n- í•µì‹¬ ê°œë… (concept): ì¡°í•­ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•œ ì§§ì€ êµ¬ë¬¸ì…ë‹ˆë‹¤.\\n- ì£¼ì²´ (subject): ê°œë…ì— ì˜í•´ ìˆ˜í–‰ë˜ëŠ” ì£¼ìš” í–‰ë™ì˜ í–‰ìœ„ìì…ë‹ˆë‹¤.\\n- í–‰ìœ„ (action): ì£¼ì²´ê°€ ìˆ˜í–‰í•˜ëŠ” ë™ì‚¬ ë˜ëŠ” ë™ì‚¬êµ¬ì…ë‹ˆë‹¤.\\n\\në§Œì•½ ì¡°í•­ ë²ˆí˜¸ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'Unknown'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ í•µì‹¬ ê°œë…ì„ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ 'Unknown'ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ ì£¼ì²´ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ nullë¡œ í‘œê¸°í•˜ì„¸ìš”.\\në§Œì•½ í–‰ìœ„ë¥¼ íŠ¹ì •í•  ìˆ˜ ì—†ìœ¼ë©´ nullë¡œ í‘œê¸°í•˜ì„¸ìš”.\\n\\n{format_instructions}\\në²•ë¥  ì¡°í•­: {article}\"\"\"),\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O8zMTxneWpp"
      },
      "source": [
        "## 5ï¸âƒ£ PDF íŒŒì¼ ì²˜ë¦¬\n",
        "\n",
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3mLJa1eeWpp"
      },
      "outputs": [],
      "source": [
        "# PDF íŒŒì¼ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    pdf_filename = list(uploaded.keys())[0]\n",
        "    print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {pdf_filename}\")\n",
        "else:\n",
        "    print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    pdf_filename = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0ktrgnreWpp"
      },
      "outputs": [],
      "source": [
        "# PDF ì²˜ë¦¬\n",
        "if pdf_filename:\n",
        "    import sys\n",
        "    sys.path.insert(0, '/content/Knowledge-graph-construction-LLM-v2/src')\n",
        "\n",
        "    from utils.pdf_processor import extract_text_from_pdf, get_pdf_metadata\n",
        "    from pathlib import Path\n",
        "    from colab_runner import process_document, display_results, save_to_json\n",
        "\n",
        "    try:\n",
        "        # PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "        print(f\"\\nğŸ“„ PDF íŒŒì¼ ì½ê¸° ì¤‘: {pdf_filename}\")\n",
        "        content = extract_text_from_pdf(pdf_filename)\n",
        "        metadata = get_pdf_metadata(pdf_filename)\n",
        "\n",
        "        print(f\"âœ… PDF ì½ê¸° ì™„ë£Œ - {len(content)} ë¬¸ì, {metadata['pages']} í˜ì´ì§€\")\n",
        "\n",
        "        # ë¬¸ì„œ ì •ë³´\n",
        "        title = metadata.get('title') or metadata.get('subject') or Path(pdf_filename).stem\n",
        "        law_number = f\"PDF ë¬¸ì„œ - {pdf_filename}\"\n",
        "\n",
        "        # ë¬¸ì„œ ì²˜ë¦¬ (ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ)\n",
        "        result = process_document(\n",
        "            title=title,\n",
        "            law_number=law_number,\n",
        "            content=content,\n",
        "            max_articles=3\n",
        "        )\n",
        "\n",
        "        # ê²°ê³¼ í‘œì‹œ\n",
        "        display_results(result)\n",
        "\n",
        "        # JSONìœ¼ë¡œ ì €ì¥\n",
        "        output_filename = f\"{Path(pdf_filename).stem}_result.json\"\n",
        "        json_path = save_to_json(result, output_filename)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"âœ¨ PDF ì²˜ë¦¬ ì™„ë£Œ!\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(\"âš ï¸ PDF íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ì…€ì„ ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KcWiBr6eWpp"
      },
      "source": [
        "## 6ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”\n",
        "\n",
        "ì¶”ì¶œëœ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7mRae5LeWpq"
      },
      "outputs": [],
      "source": [
        "# ê²°ê³¼ ì‹œê°í™”\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# JSON íŒŒì¼ ì½ê¸° (ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ íŒŒì¼)\n",
        "import glob\n",
        "json_files = glob.glob(\"*_result.json\")\n",
        "if not json_files:\n",
        "    print(\"âš ï¸ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    latest_json = max(json_files, key=lambda x: os.path.getmtime(x))\n",
        "    print(f\"ğŸ“Š ê²°ê³¼ íŒŒì¼: {latest_json}\")\n",
        "\n",
        "    with open(latest_json, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # ê´€ê³„ ìœ í˜• ë¶„í¬\n",
        "    relations = [t['relation'] for t in data['triplets']]\n",
        "    relation_counts = Counter(relations)\n",
        "\n",
        "    if relation_counts:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # ê´€ê³„ ìœ í˜• ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "        ax1.bar(range(len(relation_counts)), list(relation_counts.values()))\n",
        "        ax1.set_xticks(range(len(relation_counts)))\n",
        "        ax1.set_xticklabels(list(relation_counts.keys()), rotation=45, ha='right')\n",
        "        ax1.set_title('ê´€ê³„ ìœ í˜• ë¶„í¬')\n",
        "        ax1.set_ylabel('ê°œìˆ˜')\n",
        "\n",
        "        # ê°œì²´ í†µê³„\n",
        "        entity_stats = {\n",
        "            'ì „ì²´ ê°œì²´': len(data['entities']),\n",
        "            'ì „ì²´ ê´€ê³„': len(data['triplets']),\n",
        "            'ê³ ìœ  ê´€ê³„': len(relation_counts)\n",
        "        }\n",
        "        ax2.bar(range(len(entity_stats)), list(entity_stats.values()))\n",
        "        ax2.set_xticks(range(len(entity_stats)))\n",
        "        ax2.set_xticklabels(list(entity_stats.keys()))\n",
        "        ax2.set_title('ì¶”ì¶œ í†µê³„')\n",
        "        ax2.set_ylabel('ê°œìˆ˜')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nğŸ“Š í†µê³„:\")\n",
        "        print(f\"   - ì¶”ì¶œëœ ê°œì²´: {len(data['entities'])}ê°œ\")\n",
        "        print(f\"   - ì¶”ì¶œëœ ê´€ê³„: {len(data['triplets'])}ê°œ\")\n",
        "        print(f\"   - ê³ ìœ  ê´€ê³„ ìœ í˜•: {len(relation_counts)}ê°œ\")\n",
        "    else:\n",
        "        print(\"âš ï¸ ì¶”ì¶œëœ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIhyKlGeWpq"
      },
      "source": [
        "## 7ï¸âƒ£ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ\n",
        "\n",
        "ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2c8F7c0eWpq"
      },
      "outputs": [],
      "source": [
        "# ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "from google.colab import files\n",
        "import glob\n",
        "\n",
        "# ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°\n",
        "json_files = glob.glob(\"*_result.json\")\n",
        "\n",
        "if json_files:\n",
        "    print(\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼:\")\n",
        "    for i, file in enumerate(json_files, 1):\n",
        "        print(f\"   {i}. {file}\")\n",
        "\n",
        "    # ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "    for file in json_files:\n",
        "        print(f\"\\në‹¤ìš´ë¡œë“œ ì¤‘: {file}\")\n",
        "        files.download(file)\n",
        "\n",
        "    print(\"\\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
        "else:\n",
        "    print(\"âš ï¸ ë‹¤ìš´ë¡œë“œí•  ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSIeAlqOeWpq"
      },
      "source": [
        "## ğŸ“ ì°¸ê³ ì‚¬í•­\n",
        "\n",
        "### Colab í™˜ê²½ ì œí•œì‚¬í•­\n",
        "- ë¬´ë£Œ GPU (T4) ì‚¬ìš© ì‹œê°„ ì œí•œ ìˆìŒ\n",
        "- Gemini API ë¬´ë£Œ tierëŠ” ë¶„ë‹¹ ìš”ì²­ ì œí•œì´ ìˆìŒ\n",
        "- ëŒ€ìš©ëŸ‰ PDF ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥\n",
        "- ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì œí•œë¨ (í…ŒìŠ¤íŠ¸ ìš©ë„)\n",
        "\n",
        "### ë” ë§ì€ ì¡°í•­ ì²˜ë¦¬í•˜ê¸°\n",
        "ìœ„ ì½”ë“œì—ì„œ `max_articles=3`ì„ ì›í•˜ëŠ” ìˆ«ìë¡œ ë³€ê²½í•˜ì„¸ìš”. ë‹¨, API ì œí•œì„ ì£¼ì˜í•˜ì„¸ìš”.\n",
        "\n",
        "### ë¬¸ì œ í•´ê²°\n",
        "- API í‚¤ ì˜¤ë¥˜: Gemini API í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”\n",
        "- ë©”ëª¨ë¦¬ ë¶€ì¡±: ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ê³  ë” ì‘ì€ ë¬¸ì„œë¡œ ì‹œë„í•˜ì„¸ìš”\n",
        "- GPU ì˜¤ë¥˜: ëŸ°íƒ€ì„ ìœ í˜•ì„ \"T4 GPU\"ë¡œ ë³€ê²½í•˜ì„¸ìš”\n",
        "\n",
        "### ì „ì²´ ê¸°ëŠ¥ ì‚¬ìš©í•˜ê¸°\n",
        "Memgraphì™€ ë” ë§ì€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¡œì»¬ í™˜ê²½ì´ë‚˜ Dockerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
        "ìì„¸í•œ ë‚´ìš©ì€ [GitHub ì €ì¥ì†Œ](https://github.com/WB-Jang/Knowledge-graph-construction-LLM-v2)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}