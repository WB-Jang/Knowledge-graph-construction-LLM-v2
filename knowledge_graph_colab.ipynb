{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ Legal Knowledge Graph v2 - Google Colab Edition\n",
    "\n",
    "í•œêµ­ì–´ ë²•ë¥  ë¬¸ì„œë¥¼ Google Gemini APIë¥¼ í™œìš©í•˜ì—¬ ì§€ì‹ê·¸ë˜í”„ë¡œ ë³€í™˜í•˜ëŠ” ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥\n",
    "- âœ… GPU ê°€ì† ì§€ì› (T4)\n",
    "- âœ… Google Gemini API ì—°ë™\n",
    "- âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)\n",
    "- âœ… ë²•ë¥  ì¡°í•­ ìë™ ë¶„ë¦¬\n",
    "- âœ… ì§€ì‹ ê·¸ë˜í”„ ìƒì„±\n",
    "- âœ… ê²°ê³¼ JSON ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
    "- âœ… í•œê¸€ ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    print(\"âœ… GPU ì‚¬ìš© ê°€ëŠ¥:\")\n",
    "    print(result.stdout)\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì €ì¥ì†Œ í´ë¡ \n",
    "!git clone https://github.com/WB-Jang/Knowledge-graph-construction-LLM-v2.git\n",
    "%cd Knowledge-graph-construction-LLM-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install -q langchain langchain-community langchain-google-genai langgraph\n",
    "!pip install -q google-generativeai langchain-core\n",
    "!pip install -q pydantic python-dotenv\n",
    "!pip install -q rich tqdm\n",
    "!pip install -q PyMuPDF\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œê°í™”ìš©)\n",
    "!apt-get install -qq fonts-nanum\n",
    "!fc-cache -fv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ë‚˜ëˆ” í°íŠ¸ ì„¤ì •\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = font_prop.get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ API í‚¤ ì„¤ì •\n",
    "\n",
    "Google AI Studioì—ì„œ Gemini API í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”: https://makersuite.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Gemini API í‚¤ ì…ë ¥\n",
    "api_key = getpass(\"Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "os.environ[\"USE_LOCAL_LLM\"] = \"false\"\n",
    "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.0-flash-exp\"\n",
    "os.environ[\"LLM_TEMPERATURE\"] = \"0.0\"\n",
    "os.environ[\"LLM_MAX_TOKENS\"] = \"2048\"\n",
    "\n",
    "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Colabìš© ê°„ì†Œí™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\n",
    "\n",
    "Colab í™˜ê²½ì—ì„œëŠ” Memgraphë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ë©”ëª¨ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê°„ì†Œí™”ëœ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colabìš© ê°„ì†Œí™” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±\n",
    "colab_script = '''\n",
    "\"\"\"Colabìš© ê°„ì†Œí™” ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.insert(0, \"/content/Knowledge-graph-construction-LLM-v2/src\")\n",
    "\n",
    "from models.schemas import LegalDocument, LegalEntity, GraphTriplet\n",
    "from graphs.legal_graph import LegalKnowledgeGraphWorkflow\n",
    "from utils.text_processor import split_articles\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "console = Console()\n",
    "\n",
    "def process_document(title: str, law_number: str, content: str, max_articles: int = 3) -> LegalDocument:\n",
    "    \"\"\"ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì—¬ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    console.print(f\"\\nğŸš€ [{title}] ì²˜ë¦¬ ì‹œì‘...\", style=\"bold green\")\n",
    "    \n",
    "    # ì¡°í•­ ë¶„ë¦¬\n",
    "    articles = split_articles(content)\n",
    "    console.print(f\"ğŸ“„ ë°œê²¬ëœ ì¡°í•­: {len(articles)}ê°œ\")\n",
    "    \n",
    "    # Colabì—ì„œëŠ” ì²˜ìŒ max_articlesê°œë§Œ ì²˜ë¦¬ (API ì œí•œ ê³ ë ¤)\n",
    "    if len(articles) > max_articles:\n",
    "        console.print(f\"âš ï¸ Colab í™˜ê²½: ì²˜ìŒ {max_articles}ê°œ ì¡°í•­ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤\", style=\"yellow\")\n",
    "        content_limited = \"\\n\\n\".join(articles[:max_articles])\n",
    "    else:\n",
    "        content_limited = content\n",
    "    \n",
    "    document = LegalDocument(\n",
    "        title=title,\n",
    "        law_number=law_number,\n",
    "        content=content_limited\n",
    "    )\n",
    "    \n",
    "    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "    workflow = LegalKnowledgeGraphWorkflow()\n",
    "    \n",
    "    with console.status(\"[bold green]ì²˜ë¦¬ ì¤‘...\", spinner=\"dots\"):\n",
    "        result = workflow.process(document)\n",
    "    \n",
    "    console.print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ!\", style=\"bold green\")\n",
    "    console.print(f\"   ì¶”ì¶œëœ ê°œì²´: {len(result.entities)}ê°œ\")\n",
    "    console.print(f\"   ì¶”ì¶œëœ ê´€ê³„: {len(result.triplets)}ê°œ\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def display_results(document: LegalDocument):\n",
    "    \"\"\"ê²°ê³¼ë¥¼ í…Œì´ë¸”ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    # ê°œì²´ í…Œì´ë¸”\n",
    "    if document.entities:\n",
    "        entity_table = Table(title=f\"ğŸ“Š ì¶”ì¶œëœ ê°œì²´ ({len(document.entities)}ê°œ)\")\n",
    "        entity_table.add_column(\"ì¡°í•­\", style=\"cyan\")\n",
    "        entity_table.add_column(\"ê°œë…\", style=\"magenta\")\n",
    "        entity_table.add_column(\"ì£¼ì²´\", style=\"green\")\n",
    "        entity_table.add_column(\"í–‰ìœ„\", style=\"yellow\")\n",
    "        \n",
    "        for entity in document.entities[:10]:\n",
    "            entity_table.add_row(\n",
    "                entity.article_number,\n",
    "                entity.concept[:30],\n",
    "                entity.subject or \"-\",\n",
    "                entity.action or \"-\"\n",
    "            )\n",
    "        \n",
    "        console.print(entity_table)\n",
    "    \n",
    "    # ê´€ê³„ í…Œì´ë¸”\n",
    "    if document.triplets:\n",
    "        relation_table = Table(title=f\"ğŸ”— ì¶”ì¶œëœ ê´€ê³„ ({len(document.triplets)}ê°œ)\")\n",
    "        relation_table.add_column(\"ì£¼ì²´\", style=\"cyan\")\n",
    "        relation_table.add_column(\"ê´€ê³„\", style=\"magenta\")\n",
    "        relation_table.add_column(\"ëŒ€ìƒ\", style=\"green\")\n",
    "        relation_table.add_column(\"ì‹ ë¢°ë„\", style=\"yellow\")\n",
    "        \n",
    "        for triplet in document.triplets[:10]:\n",
    "            relation_table.add_row(\n",
    "                triplet.subject[:20],\n",
    "                triplet.relation,\n",
    "                triplet.object[:20],\n",
    "                f\"{triplet.confidence:.2f}\"\n",
    "            )\n",
    "        \n",
    "        console.print(relation_table)\n",
    "\n",
    "def save_to_json(document: LegalDocument, output_path: str = \"result.json\"):\n",
    "    \"\"\"ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    data = {\n",
    "        \"title\": document.title,\n",
    "        \"law_number\": document.law_number,\n",
    "        \"entities\": [entity.model_dump() for entity in document.entities],\n",
    "        \"triplets\": [triplet.model_dump() for triplet in document.triplets]\n",
    "    }\n",
    "    \n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    console.print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}\", style=\"bold green\")\n",
    "    return output_path\n",
    "'''\n",
    "\n",
    "# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±\n",
    "with open('colab_runner.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(colab_script)\n",
    "\n",
    "print(\"âœ… Colabìš© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ìƒ˜í”Œ ì‹¤í–‰ (ê°œì¸ì •ë³´ë³´í˜¸ë²•)\n",
    "\n",
    "ìƒ˜í”Œ ë²•ë¥  í…ìŠ¤íŠ¸ë¡œ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab ëŸ¬ë„ˆ ì„í¬íŠ¸\n",
    "import sys\n",
    "sys.path.insert(0, '/content/Knowledge-graph-construction-LLM-v2/src')\n",
    "\n",
    "from colab_runner import process_document, display_results, save_to_json\n",
    "\n",
    "# ìƒ˜í”Œ ë²•ë¥  ë¬¸ì„œ\n",
    "sample_content = \"\"\"\n",
    "ì œ1ì¡°(ëª©ì ) ì´ ë²•ì€ ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ ë° ë³´í˜¸ì— ê´€í•œ ì‚¬í•­ì„ ì •í•¨ìœ¼ë¡œì¨ ê°œì¸ì˜ ììœ ì™€ ê¶Œë¦¬ë¥¼ ë³´í˜¸í•˜ê³ , ë‚˜ì•„ê°€ ê°œì¸ì˜ ì¡´ì—„ê³¼ ê°€ì¹˜ë¥¼ êµ¬í˜„í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\n",
    "\n",
    "ì œ2ì¡°(ì •ì˜) ì´ ë²•ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "1. \"ê°œì¸ì •ë³´\"ë€ ì‚´ì•„ ìˆëŠ” ê°œì¸ì— ê´€í•œ ì •ë³´ë¡œì„œ ì„±ëª…, ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë° ì˜ìƒ ë“±ì„ í†µí•˜ì—¬ ê°œì¸ì„ ì•Œì•„ë³¼ ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ë§í•œë‹¤.\n",
    "\n",
    "ì œ3ì¡°(ê°œì¸ì •ë³´ ë³´í˜¸ ì›ì¹™) â‘  ê°œì¸ì •ë³´ì²˜ë¦¬ìëŠ” ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ ëª©ì ì„ ëª…í™•í•˜ê²Œ í•˜ì—¬ì•¼ í•˜ê³  ê·¸ ëª©ì ì— í•„ìš”í•œ ë²”ìœ„ì—ì„œ ìµœì†Œí•œì˜ ê°œì¸ì •ë³´ë§Œì„ ì ë²•í•˜ê³  ì •ë‹¹í•˜ê²Œ ìˆ˜ì§‘í•˜ì—¬ì•¼ í•œë‹¤.\n",
    "\"\"\".strip()\n",
    "\n",
    "# ë¬¸ì„œ ì²˜ë¦¬ (ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ)\n",
    "result = process_document(\n",
    "    title=\"ê°œì¸ì •ë³´ ë³´í˜¸ë²•\",\n",
    "    law_number=\"ë²•ë¥  ì œ18583í˜¸\",\n",
    "    content=sample_content,\n",
    "    max_articles=3\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ í‘œì‹œ\n",
    "display_results(result)\n",
    "\n",
    "# JSONìœ¼ë¡œ ì €ì¥\n",
    "json_path = save_to_json(result, \"sample_result.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ¨ ìƒ˜í”Œ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ PDF íŒŒì¼ ì²˜ë¦¬\n",
    "\n",
    "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF íŒŒì¼ ì—…ë¡œë“œ\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    pdf_filename = list(uploaded.keys())[0]\n",
    "    print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {pdf_filename}\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    pdf_filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF ì²˜ë¦¬\n",
    "if pdf_filename:\n",
    "    import sys\n",
    "    sys.path.insert(0, '/content/Knowledge-graph-construction-LLM-v2/src')\n",
    "    \n",
    "    from utils.pdf_processor import extract_text_from_pdf, get_pdf_metadata\n",
    "    from pathlib import Path\n",
    "    from colab_runner import process_document, display_results, save_to_json\n",
    "    \n",
    "    try:\n",
    "        # PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        print(f\"\\nğŸ“„ PDF íŒŒì¼ ì½ê¸° ì¤‘: {pdf_filename}\")\n",
    "        content = extract_text_from_pdf(pdf_filename)\n",
    "        metadata = get_pdf_metadata(pdf_filename)\n",
    "        \n",
    "        print(f\"âœ… PDF ì½ê¸° ì™„ë£Œ - {len(content)} ë¬¸ì, {metadata['pages']} í˜ì´ì§€\")\n",
    "        \n",
    "        # ë¬¸ì„œ ì •ë³´\n",
    "        title = metadata.get('title') or metadata.get('subject') or Path(pdf_filename).stem\n",
    "        law_number = f\"PDF ë¬¸ì„œ - {pdf_filename}\"\n",
    "        \n",
    "        # ë¬¸ì„œ ì²˜ë¦¬ (ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ)\n",
    "        result = process_document(\n",
    "            title=title,\n",
    "            law_number=law_number,\n",
    "            content=content,\n",
    "            max_articles=3\n",
    "        )\n",
    "        \n",
    "        # ê²°ê³¼ í‘œì‹œ\n",
    "        display_results(result)\n",
    "        \n",
    "        # JSONìœ¼ë¡œ ì €ì¥\n",
    "        output_filename = f\"{Path(pdf_filename).stem}_result.json\"\n",
    "        json_path = save_to_json(result, output_filename)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"âœ¨ PDF ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"âš ï¸ PDF íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ì…€ì„ ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "ì¶”ì¶œëœ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì‹œê°í™”\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# JSON íŒŒì¼ ì½ê¸° (ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒì„±ëœ íŒŒì¼)\n",
    "import glob\n",
    "json_files = glob.glob(\"*_result.json\")\n",
    "if not json_files:\n",
    "    print(\"âš ï¸ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    latest_json = max(json_files, key=lambda x: os.path.getmtime(x))\n",
    "    print(f\"ğŸ“Š ê²°ê³¼ íŒŒì¼: {latest_json}\")\n",
    "    \n",
    "    with open(latest_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # ê´€ê³„ ìœ í˜• ë¶„í¬\n",
    "    relations = [t['relation'] for t in data['triplets']]\n",
    "    relation_counts = Counter(relations)\n",
    "    \n",
    "    if relation_counts:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # ê´€ê³„ ìœ í˜• ë§‰ëŒ€ ê·¸ë˜í”„\n",
    "        ax1.bar(range(len(relation_counts)), list(relation_counts.values()))\n",
    "        ax1.set_xticks(range(len(relation_counts)))\n",
    "        ax1.set_xticklabels(list(relation_counts.keys()), rotation=45, ha='right')\n",
    "        ax1.set_title('ê´€ê³„ ìœ í˜• ë¶„í¬')\n",
    "        ax1.set_ylabel('ê°œìˆ˜')\n",
    "        \n",
    "        # ê°œì²´ í†µê³„\n",
    "        entity_stats = {\n",
    "            'ì „ì²´ ê°œì²´': len(data['entities']),\n",
    "            'ì „ì²´ ê´€ê³„': len(data['triplets']),\n",
    "            'ê³ ìœ  ê´€ê³„': len(relation_counts)\n",
    "        }\n",
    "        ax2.bar(range(len(entity_stats)), list(entity_stats.values()))\n",
    "        ax2.set_xticks(range(len(entity_stats)))\n",
    "        ax2.set_xticklabels(list(entity_stats.keys()))\n",
    "        ax2.set_title('ì¶”ì¶œ í†µê³„')\n",
    "        ax2.set_ylabel('ê°œìˆ˜')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í†µê³„:\")\n",
    "        print(f\"   - ì¶”ì¶œëœ ê°œì²´: {len(data['entities'])}ê°œ\")\n",
    "        print(f\"   - ì¶”ì¶œëœ ê´€ê³„: {len(data['triplets'])}ê°œ\")\n",
    "        print(f\"   - ê³ ìœ  ê´€ê³„ ìœ í˜•: {len(relation_counts)}ê°œ\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì¶”ì¶œëœ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "ì²˜ë¦¬ëœ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°\n",
    "json_files = glob.glob(\"*_result.json\")\n",
    "\n",
    "if json_files:\n",
    "    print(\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼:\")\n",
    "    for i, file in enumerate(json_files, 1):\n",
    "        print(f\"   {i}. {file}\")\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
    "    for file in json_files:\n",
    "        print(f\"\\në‹¤ìš´ë¡œë“œ ì¤‘: {file}\")\n",
    "        files.download(file)\n",
    "    \n",
    "    print(\"\\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âš ï¸ ë‹¤ìš´ë¡œë“œí•  ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ì°¸ê³ ì‚¬í•­\n",
    "\n",
    "### Colab í™˜ê²½ ì œí•œì‚¬í•­\n",
    "- ë¬´ë£Œ GPU (T4) ì‚¬ìš© ì‹œê°„ ì œí•œ ìˆìŒ\n",
    "- Gemini API ë¬´ë£Œ tierëŠ” ë¶„ë‹¹ ìš”ì²­ ì œí•œì´ ìˆìŒ\n",
    "- ëŒ€ìš©ëŸ‰ PDF ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥\n",
    "- ì²˜ìŒ 3ê°œ ì¡°í•­ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì œí•œë¨ (í…ŒìŠ¤íŠ¸ ìš©ë„)\n",
    "\n",
    "### ë” ë§ì€ ì¡°í•­ ì²˜ë¦¬í•˜ê¸°\n",
    "ìœ„ ì½”ë“œì—ì„œ `max_articles=3`ì„ ì›í•˜ëŠ” ìˆ«ìë¡œ ë³€ê²½í•˜ì„¸ìš”. ë‹¨, API ì œí•œì„ ì£¼ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "### ë¬¸ì œ í•´ê²°\n",
    "- API í‚¤ ì˜¤ë¥˜: Gemini API í‚¤ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”\n",
    "- ë©”ëª¨ë¦¬ ë¶€ì¡±: ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•˜ê³  ë” ì‘ì€ ë¬¸ì„œë¡œ ì‹œë„í•˜ì„¸ìš”\n",
    "- GPU ì˜¤ë¥˜: ëŸ°íƒ€ì„ ìœ í˜•ì„ \"T4 GPU\"ë¡œ ë³€ê²½í•˜ì„¸ìš”\n",
    "\n",
    "### ì „ì²´ ê¸°ëŠ¥ ì‚¬ìš©í•˜ê¸°\n",
    "Memgraphì™€ ë” ë§ì€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¡œì»¬ í™˜ê²½ì´ë‚˜ Dockerë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "ìì„¸í•œ ë‚´ìš©ì€ [GitHub ì €ì¥ì†Œ](https://github.com/WB-Jang/Knowledge-graph-construction-LLM-v2)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
