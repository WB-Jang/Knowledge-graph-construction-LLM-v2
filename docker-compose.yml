version: '3.8'

services:
  legal-kg:  
    build: .
    container_name: legal-knowledge-graph-v2
    
    volumes: 
      - .:/app  # 소스 코드 및 데이터 디렉토리 마운트
      - legal-kg-cache:/home/appuser/.cache
      - legal-models:/app/models
    environment:  
      # Google Gemini API 설정
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.5-flash-preview-09-2025}
      
      # LLM 설정
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.0}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-8192}
      
      # 로컬 LLM 사용 여부 (선택사항)
      - USE_LOCAL_LLM=${USE_LOCAL_LLM:-false}
      - LLAMA_CPP_API_URL=${LLAMA_CPP_API_URL:-http://host.docker.internal:8000}
      - LLAMA_CPP_API_KEY=${LLAMA_CPP_API_KEY:-}
      
      # LangChain 추적 (선택사항)
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      
      # Neo4j 설정 (host의 neo4j-local 컨테이너 사용)
      - NEO4J_URI=bolt://host.docker.internal:7687
      - NEO4J_USERNAME=${NEO4J_USERNAME:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-neo4j}
      
      # GPU 설정
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      
    ports:
      - "8888:8888"   # Jupyter (선택사항)
      - "8501:8501"   # Streamlit (선택사항)
    
    command: tail -f /dev/null
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count:  all
              capabilities: [gpu]
    
    extra_hosts: 
      - "host.docker. internal:host-gateway"

  memgraph:  # 이 부분을 추가
    image: memgraph/memgraph:latest
    container_name: legal-kg-memgraph
    ports:
      - "7687:7687"
      # - "3000:3000"
    volumes:
      - memgraph_data:/var/lib/memgraph
      - memgraph_logs:/var/log/memgraph
    environment:
      - MEMGRAPH="--log-level=TRACE --also-log-to-stderr"
    restart: unless-stopped
  memgraph-lab:  # 새로 추가
    image: memgraph/lab:latest
    container_name: legal-kg-memgraph-lab
    ports:
      - "3000:3000"
    environment:
      - MG_HOST=memgraph  # Memgraph 컨테이너와 연결
      - MG_PORT=7687
    depends_on:
      - memgraph
    restart: unless-stopped
volumes:
  legal-kg-cache:
    driver: local
  legal-models:
    driver: local
  memgraph_data:  # 이 부분을 추가
    driver: local
  memgraph_logs:  # 이 부분을 추가
    driver: local