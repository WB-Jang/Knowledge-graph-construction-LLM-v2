version: '3.8'

services:
  legal-kg:  
    build: .
    container_name: legal-knowledge-graph-v2
    volumes: 
      - . :/app
      - legal-kg-cache:/home/appuser/. cache
      - legal-models:/app/models
    environment:  
      # Google Gemini API 설정
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-your-google-api-key-here}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-2.5-flash}
      
      # LLM 설정
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.0}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-8192}
      
      # 로컬 LLM 사용 여부 (선택사항)
      - USE_LOCAL_LLM=${USE_LOCAL_LLM:-false}
      - LLAMA_CPP_API_URL=${LLAMA_CPP_API_URL:-http://host.docker.internal:8000}
      - LLAMA_CPP_API_KEY=${LLAMA_CPP_API_KEY:-}
      
      # LangChain 추적 (선택사항)
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      
      # Neo4j 설정 (host의 neo4j-local 컨테이너 사용)
      - NEO4J_URI=bolt://host.docker.internal:7687
      - NEO4J_USERNAME=${NEO4J_USERNAME:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-neo4j}
      
      # GPU 설정
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      
    ports:
      - "8888:8888"   # Jupyter (선택사항)
      - "8501:8501"   # Streamlit (선택사항)
    
    command: tail -f /dev/null
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count:  all
              capabilities: [gpu]
    
    extra_hosts: 
      - "host.docker. internal:host-gateway"

volumes:
  legal-kg-cache:
    driver: local
  legal-models:
    driver: local